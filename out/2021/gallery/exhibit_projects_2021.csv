id,submission_id,title,year,authors,collaborators,abstract,description,image1,image2,image3,image4,image5,video,material,link
0,1010,Not Suitable for Breathing,2021,Zhouyang Lu,,"Not Suitable for Breathing, a data visualization and art installation, which visualizes Canadian COVID-19 mortality data through animation, physical objects, and sound. These projects provide viewers with an opportunity to contemplate and reflect on our experiences and those we have lost during the pandemic.","Many people do not realize, nor connect emotionally to the daily COVID-19 mortality rate that they see and hear reported in the news. They do not personally know the names of the persons represented in the death toll. The numbers do speak to the lived experiences of those afflicted with and treating the disease. Behind the data are medical personnel who are afraid of infection and have been reluctant to take off their protective clothing when spending time with their loved ones at home. There are critically ill patients whose lungs are connected to machines. They are still unable to breathe. For many, their only option has been to self-isolate and die alone.

Not Suitable for Breathing is an art installation that visualizes Canadian COVID-19 mortality data through physical objects, projected animation, and sound. The installation consists of white rice paper bags, medical infusion stands, a system of air pumps and spotlights. The air pumps are programmed to inflate and deflate the bags, according to the daily number of COVID-19 deaths from Canada. Hence, the breathing of the paper bag visualizes such information. The data showing the date and daily death count is projected on a 270-degree screen using 3 projectors, with an animation showing the increase in the number of deaths using an icon of the coronavirus. The 9-channel soundscape plays an assemblage of news reports from different countries mixed with the sound of a person breathing, water, medical machines, and synthetic sounds.

Visualizing the number of COVID-19 related deaths through this project helps viewers to understand that COVID-19 has affected everyone throughout the various sectors of society.  Thus, not only governments and health institutions but everyone shares a responsibility to reflect on and help stop the spread of this pandemic.",a-visap_1010_Lu_Image5.jpg,a-visap_1010_Lu_Image1.jpg,a-visap_1010_Lu_Image2.jpg,a-visap_1010_Lu_Image3.jpg,a-visap_1010_Lu_Image4.jpg,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/53f7JkE8KJg"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>","Software, Hardware, or other",
1,1017,Invisible Lives,2021,"Hye Yeon Nam, Zak Berkowitz",,"Invisible Lives is a robotic installation using the Twitter data and customized robot fingers to evoke understanding and spark a discussion about racism and the recent social movements Black Lives Matter and Stop Asian Hate. While Invisible Lives represents sensitive social issues, it also reveals the lack of conversation.","Invisible Lives uses a computational system to evoke understanding and spark a discussion about racism and the recent social movements Black Lives Matter and Stop Asian Hate. It explores how racial biases are often freely expressed on online platforms where authors can hide behind anonymity. While we are connected online, we are also divided by biases. Biases separate people by gender, race, language, culture, and appearance. Online we are simultaneously connected and disconnected. Invisible Lives not only represents sensitive social issues but also voices the feelings of the targeted groups and reveals the lack of conversation about these issues.
Invisible Lives receives data including ID, date, time, sentences, and hashtags from Twitter in real-time, filters by keywords of Stop Asian Hate and Black Lives Matter using Python, and prints sentences on paper from a thermal printer. The process is implemented with Raspberry PI, Arduino microcontroller, stepper motors, and motor drivers. As sentences are printed, robotic hands with silicon fingers cut the thermal paper, leaving a pile of printouts on ground. As the fallen papers piled higher and higher, the audience can pick up the papers to read, take, or throw away. Amongst the pile of diverse messages, one may find examples that seek to share positive messages from the movements.
The aim of Invisible Lives is to raise awareness and start discussions, not for the audience to remain in frustration. By confronting the audience with a live stream of the on-going social movements of Black Lives Matter and Stop Asian Hate, the installation poses controversial questions about the origins, function, transmission, and lineage of prejudice. Since these robots resemble parts of the human body, yet are controlled by computational and mechanical systems, Invisible Lives reveals the different meaningful and reflective layers between human and machine.",a-visap_1017_image1.jpg,a-visap_1017_image2.jpg,a-visap_1017_image3.jpg,a-visap_1017_image4.jpg,,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/5AOS8ViW__g"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>","Robotic Installation (plastic, silicon, thermal printer, and customized hardware)",
2,1021,Roads in You,2020,Yoon C Han,"Ryan Cottone, Mehdi Heydari",Roads in You is an interactive biometric-data artwork that allows participants to scan their veins and find the roads that match their vein lines. This new artwork explores the line segmentation and the structure of veins and compares them to roads in the real world. ,"Roads in You is an interactive biometric-data artwork that allows participants to scan their veins and find the roads that match their vein lines. The vein data as one of the fascinating forms of biometric data contain uniquely complicated lines that resemble the roads and paths surrounding us. The roads resemble how our vein lines are interconnected and how the blood circulates in our bodies in various directions, at various speeds, and in different conditions. This new artwork explores the line segmentation and the structure of veins and compares them to roads in the real world. The participants can also export the data and keep them as a personalized souvenir (3d printed sculptures) as part of the artistic experience. Through this project, users can explore the correlation between individuals and environments using the hidden patterns under the skin and the vein recognition techniques, image processing and artificial intelligence. This project also has the potential to lead the way in the interpretation of complicated datasets while providing aesthetically beautiful and mesmerizing visualizations.

Project website: <a href=""http://yoonchunghan.com/roadsinyou/"" target=""_blank"">http://yoonchunghan.com/roadsinyou/</a>",a-visap_1021_RoadsInYou_Image3.jpg,a-visap_1021_RoadsInYou_Image1.jpg,a-visap_1021_RoadsInYou_Image2.jpg,a-visap_1021_RoadsInYou_Image4.jpg,a-visap_1021_RoadsInYou_Image5.png,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/k3YYXJlT2Sk"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>","D3.js, Python, Mapbox, 3D printing, variable dimension (interactive installation), 21cm x 30cm x 7cm (each 3d printed sculpture)",
3,1035,Invisible Pixel: Short Video Narratives from a Machine Perspective,2021,"Junlin Zhu, Wenxuan Zhao, Yingjing Duan, Juanjuan Long",,"Invisible Pixel is a web page based on China's Internet poverty alleviation background, aiming to explore how computer technology will affect social media in the future. The project uses machine learning to transform short video texts into images, creating a machine-perspective data narratives of rural areas.","Short video software has become a new agricultural tool for Chinese farmers to alleviate poverty in recent years. The Internet connects the urban and rural public cultural spaces, social media transforms personal expression into public communication, and the public rediscovered individual narratives in remote areas.

With the popularity of short videos, how will technological innovation further affect social media? Can the current short video-based individual narratives be objectified with algorithms? In what form will it be presented? Will it be more attractive? With such thoughts and purposes, we try to simulate the data experience of social media from a machine perspective to respond.

Invisible Pixel is a web page based on China's Internet poverty alleviation background. It selected 60 IDs information from the program Happy Village Leaders launched by the short-video platform Kwai, including five content types: specialties, tourism, life, techniques, and charity. We input the video texts of IDs into the Deep-daze model to generate images to build a visual portrait of IDs. The web page has a linear structure divided into three main views: ID map, Pixel tunnel, and Machine view. Viewers can switch between the daily viewing interface and the machine view by clicking and long-pressing the mouse.

At this stage, the machine has been able to develop its own imagination based on the dataset and make an accurate visual description. The resulting images may not meet conventional aesthetic standards, but offer the possibility of an artificial intelligence present in our future daily life.

<a href=""http://flowingboundary.com/IP"" target=""_blank"">http://flowingboundary.com/IP</a>",a-visap_1035_invisible pixel (1).jpg,a-visap_1035_invisible pixel (2).jpg,a-visap_1035_invisible pixel (3).jpg,a-visap_1035_invisible pixel (4).jpg,a-visap_1035_invisible pixel (5).jpg,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/zapltlNw1-w"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>","webGL, Unity3D, Deep-Daze",
4,1036,FaceType: Expressing Our Spoken Expression ,2021,"Kevin Maher, Fan Xiang, Liang Zhi",,"We designed the installation FaceType so that visitors could perform Chinese calligraphy, “writing” English letters that document emotion, cadence, and emphasis in audience expression. Letter shape, brush stroke, spacing and speed are “data-ink” giving viewers a sense of how their emotion had been expressed over time.","In the installation FaceType, visitors experience the emotion, cadence, and emphasis in their speech in vivid generated type. FaceType connects our facial expression with Chinese calligraphy, using dynamic emotional changes as a common point between these strangely different means of expression.

Letter shape, brush stroke, spacing and speed as to perform “data-ink” reflecting audience speech in a live process. Intuitive mapping of these factors were developed for a non-Western audience in mind, one versed with understanding of how calligraphy is used for expression. The strokes of the font were developed in collaboration with Chinese calligraphers, whose work often incorporates emotion-laden brush strokes.

During the installation showing, nearly half of the audience interacted with the work through the microphone and camera. FaceType takes the emotional intensity and valence of facial expressions as well as the emphasis and cadence in visitor speech to “write” animated strokes documenting their spoken expression.",visap_1036_image (1).jpg,visap_1036_image (2).jpg,visap_1036_image (3).jpg,visap_1036_image (4).jpg,visap_1036_image (5).jpg,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/LZN7ei-pdGE"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>","Software: Python, Tensorflow, LeonSans, D3.js, Pixi.js, Microsoft Azure
Hardware: Camera, microphone, projector, canvas, lcd screen
Dimensions: 3.6 meters by 1.4 meters",
5,1037,Decoding and Encoding of Tibetan,2021,"Anqi Song, Xintong Song, Yuhao Chen, Guangyu Luo, Qiansheng Li",,The website tells a data story from Tibetan characters to Tibetan culture in an innovative and experiential way and bring the Tibetan language into the public's eye. We want to use data visualization to build a bridge between Tibetan and Chinese cultures in order to promote the spread of Tibetan culture.,"This work takes Tibetan characters as the main body, and produces an interactive web page with data visualization and narrative. Our work will interpret the cultural value of Tibetan from the perspective of data to establish the bridge of Sino-Tibetan cultural exchanges.The web page is divided into three parts. The first part of the website is ""deconstructing Tibetan characters"", which aims to let people know the basic knowledge of the Tibetan. Analyze the origin and structure of Tibetan characters. Through the interactive page of matching strokes with signboards and Tibetan word formation games, you can quickly understand the Tibetan language knowledge and enter the Tibetan life. 
The second part of the website is “to deconstruct Tibetan calligraphy through data visualization”. We designed a comparative experiment on Tibetan writing and Chinese writing. We use wearable devices to collect data on brain waves and muscle changes of experimenters who write Tibetan calligraphy and Chinese calligraphy, as well as data such as images, videos, and writing time. We process and analyze the original data to visually show the difference and connection between Tibetan and Chinese calligraphy. 
The third part of the website is ""deconstructing text"". Tsangyang Gyatso, the most representative folk song poet in Tibet, China with his most classic work named “The Love-songs of 6th Dalai Lama Tshangyang Gyatsho"". We make the visualization analysis and emotional interpretation of 64 poems, And combine word cloud diagrams, relationship diagrams, tree diagrams, etc. for visual presentation. We observe the emotional expression of poetry from a rational point of view. 
The whole website progressively transmits information. It tells a data story from Tibetan characters to Tibetan culture in an innovative way. We want to use data visualization to build a bridge between Tibetan and Chinese cultures in order to promote the spread of Tibetan culture.",a-visap_1037_Song_Image_Material 1_1.jpg,a-visap_1037_Song_Image_Material 1_2.jpg,a-visap_1037_Song_Image_Material 1_3.jpg,a-visap_1037_Song_Image_Material 1_4.jpg,a-visap_1037_Song_Image_Material 1_5.jpg,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/swvMpMjGNOE"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>",Interactive web pages,
6,1044,Spectrographies: Decomposition of Music into Light,2021,"Baltazar P&eacute;rez, Ilana Levin",,"Cover art has always been a way for people to identify with and connect to music even in our current digital distribution times. Spectrographies proposes a new way to embody music albums. Using sound visualization as its main language, each album is translated into a “photo album” of song fingerprints.","Since designing cover art for music albums was pioneered by Alex Steinweiss by the end of the 30’s, music has become inextricably associated with the artwork that serves as its medium. Music distribution was forever changed and his designs went on to inspire future covers such as Pink Floyd’s <i>Dark Side</i>. Now that music distribution has turned mostly digital, transitioning to the new “radio” format of streaming, the image artwork has lost part of the importance it had to make people identify and connect to music in the vinyl and CD eras.

<i>Spectrographies: Decompositions of Music into Light</i> started out as an aesthetic experiment to remix famous album covers by digitally fusing sound and artwork and developed into a new way to represent and embody music, leading to a reinterpretation of the concept of cover art and physical album in the digital distribution age of music. The project works through a semiautomated process which transforms an album into a graphical edition made from its own tracks which, as photographs in a photo album, can be independently collected. A pictographic legend inspired by the Voyager Golden Record accompanies the enveloped edition of a full LP.

The technique developed for <i>Spectrographies</i> is grounded on the spectrogram (the decomposition of a signal in time into its constituent frequencies) and thus the resulting images work as a biometric fingerprint, or iris, of the song, each being totally unique and linked to its materiality. The only part of the process requiring human intervention is the design of the color schema of an album. <i>Spectrographies</i> is also suitable to create animated videos where sound and visuals are played together in a live spectral analysis to produce a synesthetic experience which transfers to its static form.

instagram: <a href=""https://www.instagram.com/spectrographies"" target=""_blank"">@spectrographies</a>",visap_1044_image (3).jpg,visap_1044_image (1).jpg,visap_1044_image (2).jpg,visap_1044_image (4).JPG,visap_1044_image (5).jpg,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/1AY94U2Wcwc"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>",,
7,1046,Glacier's Lament,2021,Jiabao Li,,"Glaciers are sentinels of climate change. They are the most visible evidence of global warming today. This series of works embodies the stunning beauty, rapid change, fragility, destructive power, and magnificence of glaciers. At the same time, they challenge the audience with the dramatic, irreversible ecological damages from climate change.","Glaciers are sentinels of climate change. They are the most visible evidence of global warming today. This series of works embodies the stunning beauty, rapid change, fragility, destructive power, and magnificence of glaciers. At the same time, they challenge the audience with the dramatic, irreversible ecological damages from climate change.
There are four color cards in PANTONE for glacier blue. However, in real glaciers, this blue color is variable and dynamic. As glaciers are disappearing, this unique blue is also disappearing. We sampled and blended the blue color from glaciers in Alaska and hung them in recycled glass vials. When one glacier calving happened, one color vial fell down. At the end of the exhibition, all 60 vials fell down, forming a painting on the canvas beneath.

In Glacier’s Lament, we used data from glacier melting in the past 60 years to compose music and dance with local musicians who have witnessed the recession of the Mendenhall glacier over their lifetimes in Juneau, Alaska. We filmed the artists performing the piece on the glacier, collaborating with the glacier’s own sounds.

Glacier’s lament attempts to express and meld the feeling of loss of ephemeral beauty of glacier with the factual evidence of climate change. The goal is that in synthesizing these two realities (the factual and the felt), the work can reach audiences beyond those directly impacted by the loss of glaciers before it is too late. At the same time, it is a love letter to an already diminished nature and mourning of that loss. Glacier’s Lament and The Disappearing Blue seek to make the impersonal data personal, and the personal experience of a changing environment heard. They recreate aesthetic dynamics of the loss of nature. ",visap_1046_image (4).jpg,visap_1046_image (3).jpg,visap_1046_image (2).jpg,visap_1046_image (1).jpg,visap_1046_image (5).png,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/_9wxSZUfXos"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>",,
8,1063,Side-view States,2021,Emily Fuhrman,,"Side-view States is an atlas visualizing the 50 U.S. state boundaries from the side. Each boundary is programmatically lifted from the physical terrain, then tilted to collapse its area, leaving a trace of its topographic contingencies. This perspectival shift collapses the distinction between border and region.","On maps of the United States, state boundaries enclose flat polygons, independent of the ground beneath. Viewed from above, the borders between state territories differently follow natural barriers, approximate the juncture of a grid, and mark the edges of the land that abuts the ocean. The lines that define them trace two-dimensional outlines not subject to the vagaries of terrain, representing instead the legal and subsequent cultural definitions of where one territory ends and another begins.
 
The traveler between U.S. states tends to experience state borders as points, not lines, encountered at the point of intersection: hearing a programmed welcome announcement through a personal GPS system when crossing from New York to New Jersey, for instance; standing in Cincinnati, looking across the Ohio River to Kentucky; or seeing a ""Welcome to California"" sign when crossing the Oregon border by car. During the COVID-19 pandemic, the concept of statehood became fragile, almost ridiculous, in contrast to the hyper-localized geography to which so many confined themselves for safety. State boundaries, already an abstract concept, served primarily as grouping methods for daily statistics detailing the presence and progression of the virus.
 
This project explores cultural boundaries as data-driven artifacts unmoored from direct experience. It presents an atlas of state boundaries programmatically lifted from the physical terrain, then rotated to collapse the distinction between region and line.

Project website: <a href=""https://emilyfuhrman.co/interactive/Y2021001/"" target=""_blank"">https://emilyfuhrman.co/interactive/Y2021001/</a>",visap_1063_image (1).jpg,visap_1063_image (2).jpg,visap_1063_image (3).jpg,visap_1063_image (4).jpg,,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/ry12WJ_vlfM"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>","Edition of 5 hardcover books, +1 AP",
9,1064,Surface Tension,2019,Caitlin & Misha,,"This is an artistic visualization driven by water data from the USA. Water supports life but can also drown and destroy. Because Earth’s surface water is interconnected, the disturbances at the specific points ripple out and interfere with each other, influencing one another and combining into a pattern of interdependence.","Surface Tension is an artistic visualization driven by fresh daily streamflow data from the United States Geological Survey (USGS). Water supports life but can also drown and destroy. People are mostly water, but the melting ice caps threaten our very existence. Harnessing this elemental force requires a balancing act and this artwork is a reflection on humanity’s fraught relationship with freshwater.

Water is often depicted as blue and beautiful, and the project problematizes this metaphor by delving into the human relationship to water and how we impact the water we need to live. As an element that is constantly in a state of flux, water is shared among people and this visualization is a response to how intrinsically linked we are to water and to each other via water. We decided to focus on freshwater, which people drink and interact with every day. All of the surface water on Earth is interconnected, and the disturbances at the specific points ripple out and interfere with each other, influencing one another and combining into an aggregate pattern of interdependence. The open source project uses publicly accessible (FAIR) data, was commissioned by NC State University, and funded by the Andrew W. Mellon Foundation.

The mapped “blobs” are the percentile data from 11K sensor stations which specifies a 'percentile' of streamflow (each site’s value compares current water level/movement to historical data for that site). Since the project caches government data you can visually compare the current and past days. For example here is June 19 2021 (during the ongoing western USA drought): <a href=""https://tinyurl.com/556hvsz8"" target=""_blank"">https://tinyurl.com/556hvsz8</a> 

Compare that to a past day or record flooding (May 3 2019): <a href=""https://tinyurl.com/8c4t9zz4"" target=""_blank"">https://tinyurl.com/8c4t9zz4</a> 
Otherwise going here shows it for the current day you visit it: <a href=""http://surface-tension.caitlinandmisha.com/"" target=""_blank"">http://surface-tension.caitlinandmisha.com/</a> 

About: <a href=""https://caitlinandmisha.com/surface-tension"" target=""_blank"">https://caitlinandmisha.com/surface-tension</a>",visap_1064_image (1).png,visap_1064_image (2).png,visap_1064_image (1).jpg,,,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/mTI9CbM5dIM"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>",,
10,1069,Untitled Interspecies Umwelten,2021,Joel Ong,,"The project <i>untitled interspecies umwelten</i> is an artistic research project exploring expanded and computer-mediated experiences of conversation with another species.  Through strategies in data viz, computer vision and AI-generated text, the project proposes the speculative intermingling of the natural and cultural worlds of bio-semiotics and extra-verbal language.","The project <i>untitled interspecies umwelten</i> is an artistic research project exploring expanded and computer-mediated experiences of conversation with another species.  Through strategies in data viz, computer vision and AI-generated text, the project proposes the speculative intermingling of the natural and cultural worlds of bio-semiotics and extra-verbal language.  Its goal is to develop an interspecies futurity through which the collaborative practices with multiple species of plants, animals, fungi and microbes may inhabit the field, scientific/engineering laboratories and studios of computational practices (in silico).  
In addition, the work is motivated to explore two emerging mythologies. The first is a familiar one – developed through prescient understanding of nonhuman systems (be it computer AI, or nonhumans) and the perspective of them as analogues for human minds. Kate Crawford speaks against this oversimplification of intelligence as an elision of the human as embodied, relational and set within wider ecologies. The second, is the myth of language as anthropocentric, verbal and utilitarian. Nature abounds with communicative structures beyond our comprehension and human-determined logic. By using simple computer systems with customizable parameters of ‘seeing’ and ‘listening’, could we formulate modes of communication that construct an interspecies <i>umwelten</i> - a multitude of semiotic traces that we may respond to?
<i>untitled interspecies umwelten</i> observes a E.gracilis community under the microscope. This freshwater alga has been well-documented for its unique morphological and behavoural qualities e.g. phototaxic (moving towards light) and metaboly (the ability to alter their shape in reaction to specific stressors). In a controlled experiment, these behaviours form a vocabulary of intent and are subsequently matched to words/emotions in a pre-selected database of text. <i>E.gracilis</i> thus steers a conversational AI system and its responses to a human conversant as a documentation of poetics between animal, machine and human communicative processes.",visap_1069_image (2).jpg,visap_1069_image (3).jpg,visap_1069_image (1).jpg,,,"<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/0rEbaHlNUWA"" title=""YouTube video player"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>","Live video stream, <i>Euglena gracilis,</i> custom AI software",
